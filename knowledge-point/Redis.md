###1.1 redis键值对

​	redis键到值的过程使用的是哈希表，时间复杂度是o(1)，但是redis的值有多中存储方式。哈希表中存的不是元素本身，而是指向元素的指针，redis底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。

​	**string** ：简单动态字符串

​	**list**：双向链表、压缩列表

​	**hash**：哈希表、压缩列表

​	**storted set**：跳表、压缩列表

​	**set**：整数数组、压缩列表

​	**通常把下面这几称为集合类型**



#####1.1.1  哈希冲突和rehash、渐进式哈希

​	当你往 Redis 中写入大量数据后，就可能发现操作有时候会突然变慢了。这其实是因为你忽略了一个潜在的风险点，那就是哈希表的冲突问题和 rehash 可能带来的操作阻塞。

 * 链式哈希：

   redis采用的是链式哈希，同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。

   * 链式哈希缺点 ：

     哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低

     

 * rehash：（两个不同大小的redis全局哈希表1 和2），三步：

   1.给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；

   2.把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；

   3.释放哈希表 1 的空间。

   * rehash缺点：

     如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据了。

 * 渐进式 rehash

   简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的entries。这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。

* 压缩列表：

  压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。

* 跳表：

  跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，可以看到，这个查找过程就是在多级索引上跳来跳去，最后定位到元素。这也正好符合“跳”表的叫法。当数据量很大时，跳表的查找复杂度就是 O(logN)。

* 总结：

  （1）Redis 之所以能快速操作键值对，一方面是因为 O(1) 复杂度的哈希表被广泛使用，包括String、Hash 和 Set，它们的操作复杂度基本由哈希表决定，另一方面，Sorted Set 也采用了 O(logN) 复杂度的跳表。

  （2）双向链表、压缩列表、整数数组、哈希表和跳表这五大底层结构。

  （3）对于String 类型来说，找到哈希桶就能直接增删改查了，所以，哈希表的 O(1) 操作复杂度也就是它的复杂度了。

  （4）底层数据结构复杂度整理

  ​          哈希表  O(1)

  ​          跳表  O(logN)

  ​          双向链表  O(N)

  ​          压缩列表  O(N)

  ​          整数数组  O(N)

  **问题**：*整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？*

​		（1）内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。



###2.1 高性能IO模型

​	**前提**：

​	Redis 是单线程，主要是指Redis 的网络 IO和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

* ***单线程的redis为啥这么快***

  （1）多线程编程模式面临的共享资源的并发访问控制问题，多线程不一定就比单线程效率更高。

  （2）redis大部分操作是在内存上完成的，内存的读写速度比磁盘要高很多

  （3）redis底层使用了很多高效的数据结构（sds、跳表、哈希表）

  （4）redis使用了高效的网络模型（epoll模型）

  

  **问题**：Redis 基本 IO 模型”图中，你觉得还有哪些潜在的性能瓶颈吗？

  ​	redis单线程io的处理的性能瓶颈主要表现在两个方面

  **1：**任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种

  ​	a：**操作bigkey：**写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除big释放内存同样会消耗大量耗时。

  ​	b：**使用复杂度过高的命令：**如：sort、sunion或者其他一些o(N)命令，当N很大的时候

  ​	c：**大量的key集中过期：**redis的过期机制也是在主线程中执行的，大量的key集中过期会导致处理一个请求时，耗时都在删除过期的key，耗时边长。 

  ​	d：**淘汰策略**：redis的淘汰策略也是在主线程中执行的，当内存超过redis上限后，每次写入都要淘汰一些key，也会造成耗时边长。

  ​	e：**aof开启always刷盘机制**：每次写入都需要把这个操作进行刷磁盘，写磁盘的速度远比写内存慢一些，会拖慢redis的性能。

  ​	f：**主从全量同步生成rdb**：虽然采用fork子进程生成数据快照，但fork这一瞬间也会阻塞整个线程的，实例遇到，阻塞时间越久。

  **2：**并发量非常大时，单线程读写客户端io数据存在新能瓶颈，虽然采用io多路复用机制，但是读写客户端数据依旧是同步io，只能单线程的依次读写客户端数据，无法利用cpu多核。

  

###3.1 AOF日志（解决实例故障后数据恢复问题）

​	redis持久化目前有两种机制：aof和rdb，aof写日志是在主线程执行的，可能会阻塞主线程。

​	**aof**：是写后日志，即Redis 是先执行命令，把数据写入内存，然后才记录日志。

​	**好处**

​		（1）aof记录时不会检查语法的正确性，一旦错误，如果先记录日志，则会记录错误日志，而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。

​		（2）它是在命令执行后才记录日志，所以不会阻塞当前的写操作。

​	**风险**

​		（1）如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。

​		（2）AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。

​	**根因**

​	这两个风险都是和 AOF 写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。



**三个改进策略**

​	（1）Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；

​	（2）Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；

​	（3）No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。



三种策略的特点

```go
|  配置项     | 写回时机  |       优点        |    缺点    |
|  --------- | ------   | ---------------- | -----------------------|
|  Always    | 同步写回  |可靠性，数据基本不丢失|每个命令都要落盘，性能影响很大
| -----------| ------   | -----------------| -----------------------|
|  Everysec  | 每秒写回  |     性能适中       |宕机时丢失1s内的数据
| -----------| -------  | -----------------| -----------------------| 
|  No        | 操作系统控制
               写回      |    性能好         |宕机时数据丢失较多
```

**总结：**

​	想要获得高性能，就选择 No 策略；

​	如果想要得到高可靠性保证，就选择Always 策略；

​	如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择Everysec 策略。

**AOF文件过大带来的性能问题**

一是，文件系统本身对文件大小有限制，无法保存过大的文件；

二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；

三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。

**AOF重写**

​	Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。

​	为什么重写机制可以把日志文件变小呢? 实际上，重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。

​	**特点**

​	（1）aof重写不是在主线程完成的，不会阻塞主线程，由后台进程bgrewriteaof 来完成。

​	（2）每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。

​	简要流程：

​	（a）发生重写时，redis主线程通过fork，产生父子两个进程

​	（b）子进程执行内存拷贝，重写父进程的aof文件

​	（c）主进程没有阻塞，同时监听最新的请求，写到新的内存和旧的aof文件（及时宕机，旧的aof文件还是安全的）

​	（d）子进程完成重写后，通知主进程，主进程将最新请求的数据追加到最新的重新aof文件

​	（e）新旧aof文件替换，后面的所有记录追加到这个问题

​	**缺点**

​	落盘时机和重写机制都是在“记日志”这一过程中发挥作用的。例如，落盘时机的选择可以避免记日志时阻塞主线程，重写可以避免日志文件过大。但是，在“用日志”的过程中，也就是使用 AOF 进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上 Redis 的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了。

​	**问题**

​	（1）AOF 日志重写的时候，是由 bgrewriteaof 子进程来完成的，不用主线程参与，我们今天说的非阻塞也是指子进程的执行不阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？

​		子进程fork的开销（数据拷贝等等）

​	（2）AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？

​		使用同一个文件，处理的时候需要控制并发处理、防止重写的时候对旧的资源造成污染。



###4.1 内存快照（解决实例故障后数据恢复问题）

​	**AOF缺点**

​		用 AOF 方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis 就会恢复得很缓慢，影响到正常使用。

​	**RDB**：就是指内存中的数据在某一个时刻的状态记录。

​	**对比**：和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复。

​	**两个问题**

​	（1）对哪些数据做快照？这关系到快照的执行效率问题；两种方式：save和bgsave

​		save：在主线程中执行，会导致阻塞；

​		bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是Redis RDB 文件生成的默认配置。

​	（2）做快照时，数据还能被增删改吗？这关系到 Redis 是否被阻塞，能否同时正常处理请求。

​		Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。

​	简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。

​	**快照频率问题**

​	如果频繁地执行全量快照，也会带来两方面的开销。

​	（1），频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。

​	（2）bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。

​	**改进**：

​		**增量快照**：做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。

​		**redis4.0改进方法**：**混合使用 AOF 日志和内存快照**

​		内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。

​	**关于 AOF 和 RDB 的选择问题**

​	（1）数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；

​	（2）如果允许分钟级别的数据丢失，可以只使用 RDB；

​	（3）如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。



###5.1 数据同步（解决主从数据同步问题，主库还在）

​	**前提**

​	AOF 和 RDB，如果 Redis 发生了宕机，它们可以分别通过回放日志和重新读入 RDB 文件的方式恢复数据，从而保证尽量少丢失数据，提升可靠性。

​	**Redis高可靠性**：数据少丢失（aof、rdb）、服务尽量少中断（增加冗余副本）

​	**主从库模式**以保证数据副本的一致，主从库之间采用的是**读写分离的方式**。

​		读操作：主库、从库都可以接收；

​		写操作：首先到主库执行，然后，主库将写操作同步给从库。

​	**redis主从库采用读写分离的方式原因**

​		对同一个key的修改落到同一个主库实例上，不涉及加锁，如果不采用读写分离，需要加锁及实例间协商修改是否完成的一系列操作，会带来额外的开销。

**主从库间如何进行第一次同步？**

​	replicaof形成主从库关系，eg：实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例2上运行，1就成为主库，2为从库。

```shell
replicaof 172.16.19.3 6379
```

**主从库间数据第一次同步的三个阶段**

​	（1）主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。

```shell
从库向主库发送：psync ?  -1 （主库的 runID、复制进度 offset，第一次不知到传这俩值）
```

​	主库FULLRESYNC响应反回主库runId、复制进度offset，从库记录这两个信息

​	（2）主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载（依赖于主库的rdb文件（为啥不用aof文件？***因为rdb文件是压缩后的二进制文件，存储大小比aof小，传输效率更高，传输后恢复数据的效率更快***））

​	（3）主库在同步的时候，会有一个 replication buffer，在同步的过程中新记录保持在此，第二步同步完成后再同步缓冲区中的数据。

​	**压力**：第一次主从同步需要同步全量数据，两个耗时：**生成rdb文件、传输rdb文件**

​		如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。

​	**改进**	主	- 从	- 从 模式（**减少一主多从的压力**）

​	**基于长连接的命令传输**：主从完成全量复制后，主从之间维护一个长连接，避免频繁建连的开销。

​	**主从库间网络断了怎么办？**

​	redis2.8之前网络断链后会全量复制，开销非常大，2.8之后采取增量复制的方式。

​	repl_backlog_buffer 是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己已经读到的位置。**

​	主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset之间的差距。在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset之间的命令操作同步给从库就行。

​	**总结**

​	主库同步的三种原理，模式：	全量复制、基于长连接的命令传播，以及增量复制。

​	全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以，我给你一个小建议：一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，我们也可以采用“主 - 从 - 从”这一级联模式，来缓解主库的压力。

​	长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。我特别建议你留意一下 repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。



###6.1 哨兵机制（解决主库挂掉的问题）

​	**背景**

​		主从库集群模式。在这个模式下，如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，进行相关的操作，但是如果主库发生故障了，那就直接会影响到从库的同步，因为从库没有相应的主库可以进行数据复制操作了。	

​		需要选择新主库面临的**三个问题**：

​	（1）主库真的挂了吗？

​	（2）该选择哪个从库作为主库？

​	（3）怎么把新主库的相关信息通知给从库和客户端呢？

​	**哨兵机制**

​		哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。

​	（1）监控：

​		定时向主从库发送ping命令，超时没返回就标记为下线状态，主库如果没返回，就判断主库下线，开启自动切换主库的流程。

​	（2）选主：

​		根据一定的规则，选出主库

​	（3）通知：

​		（a）让从库执行 replicaof 命令，和新主库建立连接，并进行数据复制。

​		（a）通知客户端，与新主库连接

​	**下线判断**

​		通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。一般哨兵的个数为奇数。

​	**选新主库**：”筛选 + 打分”

​		我们在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库

​	“筛选”：（1）除了要检查从库的当前在线状态，还要判断它之前的网络连接状态，网络连接不好的，不要筛选出来

​		使用配置项 down-after-milliseconds * 10。其中，down-aftermilliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-aftermilliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。这个时间设置的较短，哨兵越敏感，但是可能会发生不必要的切换，时间过长，误判概率较低，但是切换时间较长，业务写操作延误时间就越长。

​	“打分”：

​		（a）第一轮：优先级最高的从库得分高。

​				slave-priority 配置项，内存大小、机器配置

​		（b）第二轮：和旧主库同步程度最接近的从库得分高。

​				主库会用master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。

​		（c）第三轮：ID 号小的从库得分高。

​	**每日一问**

​		切换过程中，客户端能否正常地进行请求操作呢？如果想要应用程序不感知服务的中断，还需要哨兵或需要客户端再做些什么吗？

​		（1）如果客户端使用了读写分离，那么读请求可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间写请求会失败，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。

​		如果不想让业务部感知异常，需要加消息队列中间件，把写请求先存起来，等主从切换完成后再重新写入，但是需要业务做适配。



###7.1 哨兵集群：哨兵挂了，主从库还能切换吗？

​		哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。

​		哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。

​		除了哨兵实例，我们自己编写的应用程序也可以通过 Redis 进行消息的发布和订阅。所以，为了区分不同应用的消息，Redis 会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。

​		**哨兵和哨兵通信：**

​		__sentinel__:hello频道，不同哨兵就是通过它来相互发现，实现互相通信的。

​	**哨兵是如何知道从库的 IP 地址和端口的呢？**

​		哨兵向主库发送 INFO 命令来完成的。主库接受到这个命令后，就会把从库列表返回给哨兵。

​	**哨兵和客户端**

​	每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。



**由哪个哨兵执行主从切换？**

​	任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-downby-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。

​	一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。

​	要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。



**判断主库“客观下线”：**

​		**一个哨兵获得了仲裁所需的赞成票数后**，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 **quorum** 配置项设定的。

**选主、自主切换：**

​		（1）半数以上的赞成票（哨兵个数 N/2+1）

​		（2）拿到的票数大于等于哨兵配置文件中的quorum



###8.1 切片集群：数据增多了，是该加内存还是加实例？

​		**背景**

​		在使用 RDB 进行持久化时，Redis 会 fork 子进程来完成，fork 操作的用时和 Redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致Redis 响应变慢了。

​		切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。在实际应用 Redis 时，随着用户或业务规模的扩展，保存大量数据的情况通常是无法避免的。而切片集群，就是一个非常好的解决方案。

​		**纵向扩展**：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。就像下图中，原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后，内存增加到 24GB，磁盘增加到 150GB。

​		**横向扩展**：横向增加当前 Redis 实例的个数

​		**数据切片和实例的对应分布关系**

​			（1）首先根据键值对的 key，按照CRC16 算法计算一个 16 bit的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

​			（2）Redis会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。

​			**注意点**：在手动分配哈希槽时，需要把 16384 个槽都分配完，否则Redis 集群无法正常工作。

​		**客户端如何定位数据？**

​		（1）客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。

​		那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。







###3.1 高性能IO模型

###3.1 高性能IO模型

###3.1 高性能IO模型

###3.1 高性能IO模型

###3.1 高性能IO模型

###3.1 高性能IO模型

###3.1 高性能IO模型

###3.1 高性能IO模型

###3.1 高性能IO模型













​	